---
title: "Text Mining - Tidy - Simple analysis on Mark Twain and S. Fitzgerald - Part 3"
author: 'Nuno'
date: "4/04/2018"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

Introductory Analysis

```{r echo = FALSE, message=FALSE, warning=FALSE}
cat("\f")


rm(list=ls())

library(gutenbergr)

library(dplyr)

library(ggplot2)

library(tidyr)

library(tidytext)

library(scales)

library(stringr)

library(igraph)

library(ggraph)

library(widyr)

library(MASS)


fitzgerald <- gutenberg_download(c(805,9830,6695,4368), meta_fields = "title")



tidy_fitzgerald <- fitzgerald %>%
  unnest_tokens(word, text) %>%
  anti_join(stop_words)



tidy_fitzgerald %>% group_by(title) %>%
  count(word, sort = TRUE) %>%
  top_n(10) %>%
  ggplot(aes(reorder(word,n), n, fill = title)) +
  geom_col() +
  coord_flip() +
  facet_wrap(~title, scales = "free_y") +
  labs(x = NULL) +
  guides(fill = FALSE) +
  scale_fill_brewer(palette = "Set1")


twain <- gutenberg_download(c(245,86,3176,1837,3186), meta_fields = "title")



tidy_twain <- twain %>%
  unnest_tokens(word, text) %>%
  anti_join(stop_words)


tidy_twain %>% group_by(title) %>%
  count(word, sort = TRUE) %>%
  top_n(10) %>%
  ggplot(aes(reorder(word,n), n, fill = title)) +
  geom_col() +
  coord_flip() +
  facet_wrap(~title, scales = "free_y") +
  labs(x = NULL) +
  guides(fill = FALSE) +
  scale_fill_brewer(palette = "Set1")

```



```{r echo = FALSE, message=FALSE, warning=FALSE}

books <- gutenberg_download(c(805,9830,6695,4368,245,86,3176,1837,3186), meta_fields = "title")


tidy_books <- books %>%
  unnest_tokens(word, text) %>%
  anti_join(stop_words)



tidy_books %>%
  count(word, sort = TRUE)



tidy_books %>%
  count(word, sort = TRUE) %>%
  filter(n > 600) %>%
  mutate(word = reorder(word, n)) %>%
  ggplot(aes(word, n)) +
  geom_col() +
  xlab(NULL) +
  coord_flip()


frequency <- bind_rows(mutate(tidy_fitzgerald, author = "Scott Fitzgerald"),
                       mutate(tidy_twain, author = "Mark Twain"), 
                       mutate(tidy_books, author = "Collection")) %>% 
  mutate(word = str_extract(word, "[a-z']+")) %>%
  count(author, word) %>%
  group_by(author) %>%
  mutate(proportion = n / sum(n)) %>% 
  select(-n) %>% 
  spread(author, proportion) %>% 
  gather(author, proportion, `Scott Fitzgerald`:`Mark Twain`)



ggplot(frequency, aes(x = proportion, y = `Collection`, color = abs(`Collection` - proportion))) +
  geom_abline(color = "gray40", lty = 2) +
  geom_jitter(alpha = 0.1, size = 2.5, width = 0.3, height = 0.3) +
  geom_text(aes(label = word), check_overlap = TRUE, vjust = 1.5) +
  scale_x_log10(labels = percent_format()) +
  scale_y_log10(labels = percent_format()) +
  scale_color_gradient(limits = c(0, 0.001), low = "darkslategray4", high = "gray75") +
  facet_wrap(~author, ncol = 2) +
  theme(legend.position="none") +
  labs(y = "Collection - Both", x = NULL)




cor.test(data = frequency[frequency$author == "Scott Fitzgerald",],
         ~ proportion + `Collection`)


cor.test(data = frequency[frequency$author == "Mark Twain",], 
         ~ proportion + `Collection`)



book_words_fitzgerald <- fitzgerald %>%
  unnest_tokens(word, text) %>%
  count(title, word, sort = TRUE) %>%
  ungroup()

total_words_fitzgerald <- book_words_fitzgerald %>% 
  group_by(title) %>% 
  summarize(total = sum(n))


book_words_fitzgerald <- left_join(book_words_fitzgerald, total_words_fitzgerald)


book_words_fitzgerald


ggplot(book_words_fitzgerald, aes(n/total, fill = title)) +
  geom_histogram(show.legend = FALSE) +
  xlim(NA, 0.0009) +
  facet_wrap(~title, ncol = 2, scales = "free_y")


freq_by_rank <- book_words_fitzgerald %>% 
  group_by(title) %>% 
  mutate(rank = row_number(), 
         `term frequency` = n/total)

freq_by_rank


book_words_fitzgerald_bind <- book_words_fitzgerald %>%
  bind_tf_idf(word, title, n)

book_words_fitzgerald_bind


book_words_fitzgerald_bind %>%
  select(-total) %>%
  arrange(desc(tf_idf))


book_words_fitzgerald_bind %>%
  arrange(desc(tf_idf)) %>%
  mutate(word = factor(word, levels = rev(unique(word)))) %>% 
  group_by(title) %>% 
  top_n(10) %>% 
  ungroup %>%
  ggplot(aes(word, tf_idf, fill = title)) +
  geom_col(show.legend = FALSE) +
  labs(x = NULL, y = "tf-idf") +
  facet_wrap(~title, ncol = 2, scales = "free") +
  coord_flip()

book_words_twain <- twain %>%
  unnest_tokens(word, text) %>%
  count(title, word, sort = TRUE) %>%
  ungroup()

total_words_twain <- book_words_twain %>% 
  group_by(title) %>% 
  summarize(total = sum(n))


book_words_twain <- left_join(book_words_twain, total_words_twain)


book_words_twain


ggplot(book_words_twain, aes(n/total, fill = title)) +
  geom_histogram(show.legend = FALSE) +
  xlim(NA, 0.0009) +
  facet_wrap(~title, ncol = 2, scales = "free_y")


freq_by_rank <- book_words_twain %>% 
  group_by(title) %>% 
  mutate(rank = row_number(), 
         `term frequency` = n/total)

freq_by_rank


book_words_twain_bind <- book_words_twain %>%
  bind_tf_idf(word, title, n)

book_words_twain_bind


book_words_twain_bind %>%
  select(-total) %>%
  arrange(desc(tf_idf))


book_words_twain_bind %>%
  arrange(desc(tf_idf)) %>%
  mutate(word = factor(word, levels = rev(unique(word)))) %>% 
  group_by(title) %>% 
  top_n(10) %>% 
  ungroup %>%
  ggplot(aes(word, tf_idf, fill = title)) +
  geom_col(show.legend = FALSE) +
  labs(x = NULL, y = "tf-idf") +
  facet_wrap(~title, ncol = 2, scales = "free") +
  coord_flip()


#get_sentiments("nrc")
#get_sentiments("bing")
#get_sentiments("afinn")





```

Further Analysis
Sentiment analysis, word frequency, correlation


```{r echo = FALSE, message=FALSE, warning=FALSE}

cat("\f")


rm(list=ls())


library(gutenbergr)

library(dplyr)

library(ggplot2)

library(tidyr)

library(tidytext)

library(scales)

library(stringr)

library(igraph)

library(ggraph)

library(widyr)





fitzgerald <- gutenberg_download(c(805,9830,6695,4368), meta_fields = "title")


twain <- gutenberg_download(c(245,86,3176,1837,3186), meta_fields = "title")


tidy_fitzgerald <- fitzgerald %>%
  group_by(title) %>%
  mutate(linenumber = row_number(),
         chapter = cumsum(str_detect(text, 
                                     regex("^chapter [\\divxlc]", ignore_case = TRUE)))) %>%
  ungroup() %>%
  unnest_tokens(word, text)



tidy_twain <- twain %>%
  group_by(title) %>%
  mutate(linenumber = row_number(),
         chapter = cumsum(str_detect(text, 
                                     regex("^chapter [\\divxlc]", ignore_case = TRUE)))) %>%
  ungroup() %>%
  unnest_tokens(word, text)


```


```{r echo = FALSE, message=FALSE, warning=FALSE}


nrcjoy <- get_sentiments("nrc") %>% 
  filter(sentiment == "joy")


tidy_fitzgerald %>%
  filter() %>%
  inner_join(nrcjoy) %>%
  count(word, sort = TRUE)


tidy_twain %>%
  filter() %>%
  inner_join(nrcjoy) %>%
  count(word, sort = TRUE)



#Fitzgerald

afinn <- tidy_fitzgerald %>% 
  inner_join(get_sentiments("afinn")) %>% 
  group_by(index = linenumber %/% 80) %>% 
  summarise(sentiment = sum(score)) %>% 
  mutate(method = "AFINN")

afinn

bing_and_nrc <- bind_rows(tidy_fitzgerald %>% 
                            inner_join(get_sentiments("bing")) %>%
                            mutate(method = "Bing et al."),
                          tidy_fitzgerald %>% 
                            inner_join(get_sentiments("nrc") %>% 
                                         filter(sentiment %in% c("positive", 
                                                                 "negative"))) %>%
                            mutate(method = "NRC")) %>%
  count(method, index = linenumber %/% 80, sentiment) %>%
  spread(sentiment, n, fill = 0) %>%
  mutate(sentiment = positive - negative)

bing_and_nrc



bind_rows(afinn, 
          bing_and_nrc) %>%
  ggplot(aes(index, sentiment, fill = method)) +
  geom_col(show.legend = FALSE) +
  facet_wrap(~method, ncol = 1, scales = "free_y")



#Twain

afinn <- tidy_twain %>% 
  inner_join(get_sentiments("afinn")) %>% 
  group_by(index = linenumber %/% 80) %>% 
  summarise(sentiment = sum(score)) %>% 
  mutate(method = "AFINN")

afinn

bing_and_nrc <- bind_rows(tidy_twain %>% 
                            inner_join(get_sentiments("bing")) %>%
                            mutate(method = "Bing et al."),
                          tidy_twain %>% 
                            inner_join(get_sentiments("nrc") %>% 
                                         filter(sentiment %in% c("positive", 
                                                                 "negative"))) %>%
                            mutate(method = "NRC")) %>%
  count(method, index = linenumber %/% 80, sentiment) %>%
  spread(sentiment, n, fill = 0) %>%
  mutate(sentiment = positive - negative)

bing_and_nrc



bind_rows(afinn, 
          bing_and_nrc) %>%
  ggplot(aes(index, sentiment, fill = method)) +
  geom_col(show.legend = FALSE) +
  facet_wrap(~method, ncol = 1, scales = "free_y")




get_sentiments("nrc") %>% 
  filter(sentiment %in% c("positive", 
                          "negative")) %>% 
  count(sentiment)

get_sentiments("bing") %>% 
  count(sentiment)


bing_word_counts_fitzgerald <- tidy_fitzgerald %>%
  inner_join(get_sentiments("bing")) %>%
  count(word, sentiment, sort = TRUE) %>%
  ungroup()


bing_word_counts_fitzgerald


bing_word_counts_twain <- tidy_twain %>%
  inner_join(get_sentiments("bing")) %>%
  count(word, sentiment, sort = TRUE) %>%
  ungroup()

bing_word_counts_twain



bing_word_counts_fitzgerald %>%
  group_by(sentiment) %>% top_n(10) %>% ungroup() %>% mutate(word = reorder(word, n)) %>%
  ggplot(aes(word, n, fill = sentiment)) + geom_col(show.legend = FALSE) +
  facet_wrap(~sentiment, scales = "free_y") + labs(y = "Contribution to sentiment", 
                                                   x = NULL) + coord_flip()



bing_word_counts_twain %>%
  group_by(sentiment) %>% top_n(10) %>% ungroup() %>% mutate(word = reorder(word, n)) %>%
  ggplot(aes(word, n, fill = sentiment)) + geom_col(show.legend = FALSE) +
  facet_wrap(~sentiment, scales = "free_y") + labs(y = "Contribution to sentiment", 
                                                   x = NULL) + coord_flip()

#categorization seems to be correct


```

By chapter
```{r echo = FALSE, message=FALSE, warning=FALSE}




fitzgerald_chapters <- fitzgerald %>%
  group_by("title") %>%
  unnest_tokens(chapter, text, token = "regex", 
                pattern = "Chapter|CHAPTER [\\dIVXLC]") %>%
  ungroup()

fitzgerald_chapters %>% 
  group_by(title) %>% 
  summarise(chapters = n())



twain_chapters <- twain %>%
  group_by("title") %>%
  unnest_tokens(chapter, text, token = "regex", 
                pattern = "Chapter|CHAPTER [\\dIVXLC]") %>%
  ungroup()

twain_chapters %>% 
  group_by(title) %>% 
  summarise(chapters = n())






# division into documents, each representing one chapter

by_chapter_fitzgerald <- fitzgerald %>%
  group_by(title) %>%
  mutate(chapter = cumsum(str_detect(text, regex("^chapter ", ignore_case = TRUE)))) %>%
  ungroup() %>%
  filter(chapter > 0) %>%
  unite(document, title, chapter)


by_chapter_twain <- twain %>%
  group_by(title) %>%
  mutate(chapter = cumsum(str_detect(text, regex("^chapter ", ignore_case = TRUE)))) %>%
  ungroup() %>%
  filter(chapter > 0) %>%
  unite(document, title, chapter)


# split intowords
by_chapter_word_fitzgerald <- by_chapter_fitzgerald %>%
  unnest_tokens(word, text)


by_chapter_word_twain <- by_chapter_twain %>%
  unnest_tokens(word, text)


# document-word counts
word_counts_fitzgerald <- by_chapter_word_fitzgerald %>%
  anti_join(stop_words) %>%
  count(document, word, sort = TRUE) %>%
  ungroup()

word_counts_fitzgerald



word_counts_twain <- by_chapter_word_twain %>%
  anti_join(stop_words) %>%
  count(document, word, sort = TRUE) %>%
  ungroup()

word_counts_twain


```

LDA
Topic Analysis

```{r echo = FALSE, message=FALSE, warning=FALSE}

#LDA on chapters
#Document Term Matrix

set.seed(123)

chapters_dtm_fitzgerald <- word_counts_fitzgerald %>%
  cast_dtm(document, word, n)

chapters_dtm_fitzgerald


chapters_dtm_twain <- word_counts_twain %>%
  cast_dtm(document, word, n)

chapters_dtm_twain




#using lda() to create a k-topic model. Usually we could assess the number of topics by the number of books under analysis, 
#assuming that each one of them covers a different topic. In this case considering that the books are from the same authors and 
#based on the kind of language and word-frequency we may say that may cover only a couple of topics
#Let's consider 2-3 topics. K needs to be higher than 1


library(MASS)
#2 topics
chapters_lda_fitzgerald <- lda(chapters_dtm_fitzgerald, k = 2, control = list(seed = 123))
chapters_lda_fitzgerald

chapter_topics_fitzgerald <- tidy(chapters_lda_fitzgerald, matrix = "beta")
chapter_topics_fitzgerald

chapters_lda_twain <- LDA(chapters_dtm_twain, k = 2, control = list(seed = 123))
chapters_lda_twain

chapter_topics_twain <- tidy(chapters_lda_twain, matrix = "beta")
chapter_topics_twain


#3 topics
chapters_lda_fitzgerald_k3 <- LDA(chapters_dtm_fitzgerald, k = 3, control = list(seed = 123))
chapters_lda_fitzgerald_k3

chapter_topics_fitzgerald_k3 <- tidy(chapters_lda_fitzgerald_k3, matrix = "beta")
chapter_topics_fitzgerald_k3


chapters_lda_twain_k3 <- LDA(chapters_dtm_twain, k = 3, control = list(seed = 123))
chapters_lda_twain_k3

chapter_topics_twain_k3 <- tidy(chapters_lda_twain_k3, matrix = "beta")
chapter_topics_twain_k3


# For both authors we can notice than considering 3 topics, the individual probabilities get lower


#Using dplyr's top_n() to check the top 5 terms within each topic

top_terms_fitzgerald <- chapter_topics_fitzgerald %>%
  group_by(topic) %>%
  top_n(5, beta) %>%
  ungroup() %>%
  arrange(topic, -beta)

top_terms_fitzgerald

top_terms_fitzgerald_k3 <- chapter_topics_fitzgerald_k3 %>%
  group_by(topic) %>%
  top_n(5, beta) %>%
  ungroup() %>%
  arrange(topic, -beta)

top_terms_fitzgerald_k3


top_terms_twain <- chapter_topics_twain %>%
  group_by(topic) %>%
  top_n(5, beta) %>%
  ungroup() %>%
  arrange(topic, -beta)

top_terms_twain

top_terms_twain_k3 <- chapter_topics_twain_k3 %>%
  group_by(topic) %>%
  top_n(5, beta) %>%
  ungroup() %>%
  arrange(topic, -beta)

top_terms_twain_k3


```


Unsupervised Clustering

Misclassification

```{r echo = FALSE, message=FALSE, warning=FALSE}


#Unsupervised clustering

chapters_gamma_fitzgerald <- tidy(chapters_lda_fitzgerald, matrix = "gamma")

chapters_gamma_fitzgerald

chapters_gamma_fitzgerald_mod <- chapters_gamma_fitzgerald %>%
  separate(document, c("title", "chapter"), sep = "_", convert = TRUE)

chapters_gamma_fitzgerald_mod



chapters_gamma_twain <- tidy(chapters_lda_twain, matrix = "gamma")

chapters_gamma_twain

chapters_gamma_twain_mod <- chapters_gamma_twain %>%
  separate(document, c("title", "chapter"), sep = "_", convert = TRUE)

chapters_gamma_twain_mod


#we can see that there is some misclassification, specially due to the fact that the books cover similar topics using similar language


chapters_gamma_fitzgerald_mod %>%
  mutate(title = reorder(title, gamma * topic)) %>%
  ggplot(aes(factor(topic), gamma)) +
  geom_boxplot() +
  facet_wrap(~ title)



chapter_classifications_fitzgerald <- chapters_gamma_fitzgerald_mod %>%
  group_by(title, chapter) %>%
  top_n(1, gamma) %>%
  ungroup()

chapter_classifications_fitzgerald


chapters_gamma_twain_mod %>%
  mutate(title = reorder(title, gamma * topic)) %>%
  ggplot(aes(factor(topic), gamma)) +
  geom_boxplot() +
  facet_wrap(~ title)



chapter_classifications_twain <- chapters_gamma_twain_mod %>%
  group_by(title, chapter) %>%
  top_n(1, gamma) %>%
  ungroup()

chapter_classifications_twain

#check which were most often misidentified

book_topics_fitzgerald <- chapter_classifications_fitzgerald %>%
  count(title, topic) %>%
  group_by(title) %>%
  top_n(1, n) %>%
  ungroup() %>%
  transmute(consensus = title, topic)

chapter_classifications_fitzgerald %>%
  inner_join(book_topics_fitzgerald, by = "topic") %>%
  filter(title != consensus)



book_topics_twain <- chapter_classifications_twain %>%
  count(title, topic) %>%
  group_by(title) %>%
  top_n(1, n) %>%
  ungroup() %>%
  transmute(consensus = title, topic)

chapter_classifications_twain %>%
  inner_join(book_topics_twain, by = "topic") %>%
  filter(title != consensus)

```


Augment

```{r echo = FALSE, message=FALSE, warning=FALSE}


#Augment
#Fitzgerald
assignments_fitzgerald <- augment(chapters_lda_fitzgerald, data = chapters_dtm_fitzgerald)
assignments_fitzgerald


assignments_fitzgerald <- assignments_fitzgerald %>%
  separate(document, c("title", "chapter"), sep = "_", convert = TRUE) %>%
  inner_join(book_topics_fitzgerald, by = c(".topic" = "topic"))

assignments_fitzgerald

# we can see that some of the words from "The Beautiful and Damned" were not not correctly assigned.


assignments_fitzgerald %>%
  count(title, consensus, wt = count) %>%
  group_by(title) %>%
  mutate(percent = n / sum(n)) %>%
  ggplot(aes(consensus, title, fill = percent)) +
  geom_tile() +
  scale_fill_gradient2(high = "blue", label = percent_format()) +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 90, hjust = 1),
        panel.grid = element_blank()) +
  labs(x = "Book words were assigned to",
       y = "Book words came from",
       fill = "% of assignments")


#Twain

assignments_twain <- augment(chapters_lda_twain, data = chapters_dtm_twain)
assignments_twain


assignments_twain <- assignments_twain %>%
  separate(document, c("title", "chapter"), sep = "_", convert = TRUE) %>%
  inner_join(book_topics_twain, by = c(".topic" = "topic"))

assignments_twain

# we can see that "Innocents abroad" is the book in which we've gotten best results

assignments_twain %>%
  count(title, consensus, wt = count) %>%
  group_by(title) %>%
  mutate(percent = n / sum(n)) %>%
  ggplot(aes(consensus, title, fill = percent)) +
  geom_tile() +
  scale_fill_gradient2(high = "blue", label = percent_format()) +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 90, hjust = 1),
        panel.grid = element_blank()) +
  labs(x = "Book words were assigned to",
       y = "Book words came from",
       fill = "% of assignments")



#Identification of misclassifications


wrong_words_fitzgerald <- assignments_fitzgerald %>%
  filter(title != consensus)

wrong_words_fitzgerald

wrong_words_fitzgerald %>%
  count(title, consensus, term, wt = count) %>%
  ungroup() %>%
  arrange(desc(n))


wrong_words_twain <- assignments_twain %>%
  filter(title != consensus)

wrong_words_twain

wrong_words_twain %>%
  count(title, consensus, term, wt = count) %>%
  ungroup() %>%
  arrange(desc(n))


```

N-Grams and correlation


```{r echo = FALSE, message=FALSE, warning=FALSE}

#####N-Grams and Correlations


#bigram-Fitzgerald

fitzgerald_bigrams <- fitzgerald %>% 
  unnest_tokens(bigram, text, token="ngrams", n=2)


fitzgerald_bigrams

# we can see that there is an overlap, for instance "this side" and "side of" and " of paradise"

fitzgerald_bigrams %>% 
  count(bigram, sort = TRUE)

bigrams_separated_fitzgerald <- fitzgerald_bigrams %>%
  separate(bigram, c("word1","word2"),sep=" ")

bigrams_filtered_fitzgerald <- bigrams_separated_fitzgerald %>%
  filter(!word1 %in% stop_words$word) %>%
  filter(!word2 %in% stop_words$word)

bigram_counts_fitzgerald <- bigrams_filtered_fitzgerald %>%
  count(word1,word2,sort=TRUE)

bigram_counts_fitzgerald


#bigram-Twain

twain_bigrams <- twain %>% 
  unnest_tokens(bigram, text, token="ngrams", n=2)


twain_bigrams

# we can see that there is an overlap, for instance "a connecticut" and "connecticut yankee" and "yankee in"

twain_bigrams %>% 
  count(bigram, sort = TRUE)

bigrams_separated_twain <- twain_bigrams %>%
  separate(bigram, c("word1","word2"),sep=" ")

bigrams_filtered_twain <- bigrams_separated_twain %>%
  filter(!word1 %in% stop_words$word) %>%
  filter(!word2 %in% stop_words$word)

bigram_counts_twain <- bigrams_filtered_twain %>%
  count(word1,word2,sort=TRUE)

bigram_counts_twain


#trigram-Fitzgerald

fitzgerald_trigrams <- fitzgerald %>% 
  unnest_tokens(trigram, text, token="ngrams", n=3) %>%
  separate(trigram, c("word1","word2","word3"),sep=" ") %>%
  filter(!word1 %in% stop_words$word,
        !word2 %in% stop_words$word,
        !word3 %in% stop_words$word) %>%
  count(word1, word2, word3, sort=TRUE)


#trigram-twain

twain_trigrams <- twain %>% 
  unnest_tokens(trigram, text, token="ngrams", n=3) %>%
  separate(trigram, c("word1","word2","word3"),sep=" ") %>%
  filter(!word1 %in% stop_words$word,
         !word2 %in% stop_words$word,
         !word3 %in% stop_words$word) %>%
  count(word1, word2, word3, sort=TRUE)


###tf-idf analysis in bigrams


#Fitzgerald
bigram_td_idf_fitzgerald <- fitzgerald_bigrams %>%
  count(title,bigram) %>%
  bind_tf_idf(bigram,title,n) %>%
  arrange(desc(tf_idf))

bigram_td_idf_fitzgerald

#twain

bigram_td_idf_twain <- twain_bigrams %>%
  count(title,bigram) %>%
  bind_tf_idf(bigram,title,n) %>%
  arrange(desc(tf_idf))

bigram_td_idf_twain


```

Sentiment Analysis

```{r echo = FALSE, message=FALSE, warning=FALSE}

#Sentiment Analysis - context provided by bigrams

bigrams_separated_fitzgerald %>%
  filter(word1 == "not") %>%
  count(word1,word2,sort = TRUE)


bigrams_separated_twain %>%
  filter(word1 == "not") %>%
  count(word1,word2,sort = TRUE)


#using AFINN lexicon

AFINN <- get_sentiments("afinn")

not_words_fitzgerald <- bigrams_separated_fitzgerald %>%
  filter(word1 == "not") %>%
  inner_join(AFINN, by = c(word2 = "word")) %>%
  count(word2,score,sort=TRUE) %>%
  ungroup()

not_words_fitzgerald


not_words_twain <- bigrams_separated_twain %>%
  filter(word1 == "not") %>%
  inner_join(AFINN, by = c(word2 = "word")) %>%
  count(word2,score,sort=TRUE) %>%
  ungroup()

not_words_twain

# we can see that "not" is associated with like several times, being this way able to biase our sentiment analysis.

#Assessing which words contributed the most in the "wrond" direction

not_words_fitzgerald %>%
  mutate(contribution = n * score) %>% 
  arrange(desc(abs(contribution))) %>%
  head(20) %>%
  mutate(word2 = reorder(word2,contribution)) %>%
  ggplot(aes(word2, n * score, fill = n * score > 0)) + 
  geom_col(show.legend = FALSE) + 
  xlab("words preceded by \"not\"") +
  ylab("sentiment score * number of occurrences") +
  coord_flip()


not_words_twain %>%
  mutate(contribution = n * score) %>% 
  arrange(desc(abs(contribution))) %>%
  head(20) %>%
  mutate(word2 = reorder(word2,contribution)) %>%
  ggplot(aes(word2, n * score, fill = n * score > 0)) + 
  geom_col(show.legend = FALSE) + 
  xlab("words preceded by \"not\"") +
  ylab("sentiment score * number of occurrences") +
  coord_flip()


#Biagrams "not like", "not good", "not help", "not impressed" and "not care" are the largest causes of misidentification. 
#in this cases the outcome is an idea that the text is more positive than it really is


#Using other common words that negate the subsequent term

negation_words <- c("not", "no", "never", "without")

negated_words_fitzgerald <- bigrams_separated_fitzgerald %>%
  filter(word1 %in% negation_words) %>%
  inner_join(AFINN, by = c(word2 = "word")) %>%
  count(word1, word2, score, sort = TRUE) %>%
  ungroup()

negated_words_fitzgerald

negated_words_twain <- bigrams_separated_twain %>%
  filter(word1 %in% negation_words) %>%
  inner_join(AFINN, by = c(word2 = "word")) %>%
  count(word1, word2, score, sort = TRUE) %>%
  ungroup()

negated_words_twain


negated_words_fitzgerald %>%
  mutate(contribution = n * score) %>% 
  arrange(desc(abs(contribution))) %>%
  head(20) %>%
  mutate(word2 = reorder(word2,contribution)) %>%
  ggplot(aes(word2, n * score, fill = n * score > 0)) + 
  geom_col(show.legend = FALSE) + 
  xlab("words preceded by \"negated words\"") +
  ylab("sentiment score * number of occurrences") +
  coord_flip()



negated_words_twain %>%
  mutate(contribution = n * score) %>% 
  arrange(desc(abs(contribution))) %>%
  head(20) %>%
  mutate(word2 = reorder(word2,contribution)) %>%
  ggplot(aes(word2, n * score, fill = n * score > 0)) + 
  geom_col(show.legend = FALSE) + 
  xlab("words preceded by \"negated words\"") +
  ylab("sentiment score * number of occurrences") +
  coord_flip()



bigram_graph_fitzgerald <- bigram_counts_fitzgerald %>%
  filter(n>20) %>%
  graph_from_data_frame()


bigram_graph_fitzgerald


bigram_graph_twain <- bigram_counts_twain %>%
  filter(n>20) %>%
  graph_from_data_frame()


bigram_graph_twain


set.seed(123)

ggraph(bigram_graph_fitzgerald, layout = "fr") +
  geom_edge_link() +
  geom_node_point() + 
  geom_node_text(aes(label=name), vjust = 1,hjust =1)


ggraph(bigram_graph_twain, layout = "fr") +
  geom_edge_link() +
  geom_node_point() + 
  geom_node_text(aes(label=name), vjust = 1,hjust =1)


#tweaking the graph

set.seed(123)

a <- grid::arrow(type = "closed", length = unit(.15, "inches"))

ggraph(bigram_graph_fitzgerald, layout = "fr") + 
  geom_edge_link(aes(edge_alpha = n), show.legend = FALSE,
                 arrow = a, end_cap = circle(.07, 'inches')) +
  geom_node_point(color="lightblue", size=5)+
    geom_node_text(aes(label = name), vjust = 1, hjust = 1)+
    theme_void()
                 

ggraph(bigram_graph_twain, layout = "fr") + 
  geom_edge_link(aes(edge_alpha = n), show.legend = FALSE,
                 arrow = a, end_cap = circle(.07, 'inches')) +
  geom_node_point(color="lightblue", size=5)+
  geom_node_text(aes(label = name), vjust = 1, hjust = 1)+
  theme_void()
  
  
```

  
  Pairs of words - Count and correlation

  
```{r}


fitzgerald_section_words <- fitzgerald %>%
  filter() %>%
  mutate(section = row_number() %/% 10) %>%
  filter(section >0) %>%
  unnest_tokens(word, text) %>%
  filter(!word %in% stop_words$word)


fitzgerald_section_words


twain_section_words <- twain %>%
  filter() %>%
  mutate(section = row_number() %/% 10) %>%
  filter(section >0) %>%
  unnest_tokens(word, text) %>%
  filter(!word %in% stop_words$word)


twain_section_words


word_pairs_fitzgerald <- fitzgerald_section_words %>%
  pairwise_count(word, section, sort= TRUE)

word_pairs_fitzgerald


word_pairs_twain <- twain_section_words %>%
  pairwise_count(word, section, sort= TRUE)


word_pairs_twain




#time, day, people, hundred, night, day, head,Anthony, Maury, eyes

word_cors_fitzgerald <- fitzgerald_section_words %>%
  group_by(word) %>%
  filter(n() >= 20) %>%
  pairwise_cor(word, section, sort=TRUE)



word_cors_fitzgerald %>%
  filter(item1 %in% c("anthony", "time", "eyes", "amory", "night")) %>%
  group_by(item1) %>%
  top_n(6) %>%
  ungroup() %>%
  mutate(item2 = reorder(item2, correlation)) %>%
  ggplot(aes(item2, correlation)) +
  geom_bar(stat = "identity") + 
  facet_wrap(~item1, scales = "free") +
  coord_flip()



word_cors_twain <- twain_section_words %>%
  group_by(word) %>%
  filter(n() >= 20) %>%
  pairwise_cor(word, section, sort=TRUE)



word_cors_twain %>%
  filter(item1 %in% c("time", "day", "people", "hundred", "night", "day", "head")) %>%
  group_by(item1) %>%
  top_n(6) %>%
  ungroup() %>%
  mutate(item2 = reorder(item2, correlation)) %>%
  ggplot(aes(item2, correlation)) +
  geom_bar(stat = "identity") + 
  facet_wrap(~item1, scales = "free") +
  coord_flip()


#correlation >0.25 Fitzgerald and >0.3 Twain

set.seed(123)

word_cors_fitzgerald %>%
  filter(correlation >.25) %>%
  graph_from_data_frame() %>%
  ggraph(layout = "fr") +
  geom_edge_link(aes(edge_alpha = correlation), show.legend=FALSE) +
  geom_node_point(color = "lightblue", size = 4) +
  geom_node_text(aes(label = name), repel = TRUE) +
  theme_void()


word_cors_twain %>%
  filter(correlation >.3) %>%
  graph_from_data_frame() %>%
  ggraph(layout = "fr") +
  geom_edge_link(aes(edge_alpha = correlation), show.legend=FALSE) +
  geom_node_point(color = "lightblue", size = 4) +
  geom_node_text(aes(label = name), repel = TRUE) +
  theme_void()

```

